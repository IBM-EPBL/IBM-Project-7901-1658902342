{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "IMAGE AUGMENTATION\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nimport scipy\ntrain_datagen=ImageDataGenerator(rescale=1./255, zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\ntest_datagen=ImageDataGenerator(rescale=1./255)\nx_train=train_datagen.flow_from_directory(r\"C:\\Users\\Dell\\PycharmProjects\\ibm-projectfiles\\flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)\nFound 4317 images belonging to 5 classes.\nx_test=test_datagen.flow_from_directory(r\"C:\\Users\\Dell\\PycharmProjects\\ibm-projectfiles\\flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)\nFound 4317 images belonging to 5 classes.\nx_train.class_indices\n{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\nINITIALIZING CNN AND CREATE MODEL\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D,Flatten\nADD LAYERS\nmodel=Sequential()\nINPUT LAYERS (CONVOLUTION ,MAXPOOLING,FLATTEN)\nmodel.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.summary()\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 62, 62, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n )                                                               \n                                                                 \n flatten (Flatten)           (None, 30752)             0         \n                                                                 \n=================================================================\nTotal params: 896\nTrainable params: 896\nNon-trainable params: 0\n_________________________________________________________________\nHIDDEN LAYERS\nmodel.add(Dense(300,activation='relu'))\nmodel.add(Dense(150,activation='relu'))\nOUTPUT LAYERS\nmodel.add(Dense(5,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nlen(x_train)\n180\nTRAIN THE MODEL\nmodel.fit_generator(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 30)\nC:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_13588\\3822225211.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 30)\nEpoch 1/30\n180/180 [==============================] - 59s 324ms/step - loss: 1.3304 - accuracy: 0.4656 - val_loss: 1.1759 - val_accuracy: 0.5119\nEpoch 2/30\n180/180 [==============================] - 37s 204ms/step - loss: 1.0613 - accuracy: 0.5719 - val_loss: 0.9958 - val_accuracy: 0.6090\nEpoch 3/30\n180/180 [==============================] - 37s 204ms/step - loss: 0.9628 - accuracy: 0.6280 - val_loss: 0.9222 - val_accuracy: 0.6310\nEpoch 4/30\n180/180 [==============================] - 81s 453ms/step - loss: 0.8872 - accuracy: 0.6583 - val_loss: 0.8400 - val_accuracy: 0.6873\nEpoch 5/30\n180/180 [==============================] - 32s 175ms/step - loss: 0.8313 - accuracy: 0.6817 - val_loss: 0.7703 - val_accuracy: 0.6982\nEpoch 6/30\n180/180 [==============================] - 32s 175ms/step - loss: 0.7571 - accuracy: 0.7160 - val_loss: 0.8335 - val_accuracy: 0.6919\nEpoch 7/30\n180/180 [==============================] - 38s 208ms/step - loss: 0.7302 - accuracy: 0.7278 - val_loss: 0.6824 - val_accuracy: 0.7406\nEpoch 8/30\n180/180 [==============================] - 34s 190ms/step - loss: 0.6682 - accuracy: 0.7433 - val_loss: 0.6415 - val_accuracy: 0.7579\nEpoch 9/30\n180/180 [==============================] - 35s 192ms/step - loss: 0.6360 - accuracy: 0.7593 - val_loss: 0.5899 - val_accuracy: 0.7748\nEpoch 10/30\n180/180 [==============================] - 37s 205ms/step - loss: 0.6031 - accuracy: 0.7779 - val_loss: 0.5688 - val_accuracy: 0.7867\nEpoch 11/30\n180/180 [==============================] - 37s 206ms/step - loss: 0.5528 - accuracy: 0.7920 - val_loss: 0.5298 - val_accuracy: 0.7999\nEpoch 12/30\n180/180 [==============================] - 38s 213ms/step - loss: 0.5266 - accuracy: 0.8036 - val_loss: 0.4875 - val_accuracy: 0.8216\nEpoch 13/30\n180/180 [==============================] - 40s 223ms/step - loss: 0.4710 - accuracy: 0.8244 - val_loss: 0.3977 - val_accuracy: 0.8545\nEpoch 14/30\n180/180 [==============================] - 37s 204ms/step - loss: 0.4572 - accuracy: 0.8339 - val_loss: 0.3443 - val_accuracy: 0.8805\nEpoch 15/30\n180/180 [==============================] - 33s 186ms/step - loss: 0.4404 - accuracy: 0.8385 - val_loss: 0.3241 - val_accuracy: 0.8865\nEpoch 16/30\n180/180 [==============================] - 40s 224ms/step - loss: 0.3962 - accuracy: 0.8534 - val_loss: 0.3086 - val_accuracy: 0.8909\nEpoch 17/30\n180/180 [==============================] - 39s 216ms/step - loss: 0.3749 - accuracy: 0.8631 - val_loss: 0.3248 - val_accuracy: 0.8795\nEpoch 18/30\n180/180 [==============================] - 38s 212ms/step - loss: 0.3312 - accuracy: 0.8800 - val_loss: 0.2361 - val_accuracy: 0.9222\nEpoch 19/30\n180/180 [==============================] - 38s 209ms/step - loss: 0.3155 - accuracy: 0.8830 - val_loss: 0.2159 - val_accuracy: 0.9284\nEpoch 20/30\n180/180 [==============================] - 37s 208ms/step - loss: 0.3138 - accuracy: 0.8879 - val_loss: 0.2100 - val_accuracy: 0.9280\nEpoch 21/30\n180/180 [==============================] - 36s 203ms/step - loss: 0.2905 - accuracy: 0.8902 - val_loss: 0.1868 - val_accuracy: 0.9358\nEpoch 22/30\n180/180 [==============================] - 31s 170ms/step - loss: 0.2897 - accuracy: 0.9020 - val_loss: 0.1553 - val_accuracy: 0.9500\nEpoch 23/30\n180/180 [==============================] - 30s 166ms/step - loss: 0.2602 - accuracy: 0.9143 - val_loss: 0.1516 - val_accuracy: 0.9474\nEpoch 24/30\n180/180 [==============================] - 33s 183ms/step - loss: 0.2086 - accuracy: 0.9280 - val_loss: 0.1440 - val_accuracy: 0.9532\nEpoch 25/30\n180/180 [==============================] - 33s 186ms/step - loss: 0.2183 - accuracy: 0.9238 - val_loss: 0.2480 - val_accuracy: 0.9145\nEpoch 26/30\n180/180 [==============================] - 33s 182ms/step - loss: 0.1992 - accuracy: 0.9335 - val_loss: 0.1656 - val_accuracy: 0.9465\nEpoch 27/30\n180/180 [==============================] - 33s 185ms/step - loss: 0.2076 - accuracy: 0.9273 - val_loss: 0.1522 - val_accuracy: 0.9497\nEpoch 28/30\n180/180 [==============================] - 34s 190ms/step - loss: 0.2219 - accuracy: 0.9261 - val_loss: 0.1534 - val_accuracy: 0.9504\nEpoch 29/30\n180/180 [==============================] - 35s 197ms/step - loss: 0.1702 - accuracy: 0.9400 - val_loss: 0.1536 - val_accuracy: 0.9493\nEpoch 30/30\n180/180 [==============================] - 33s 184ms/step - loss: 0.1653 - accuracy: 0.9460 - val_loss: 0.1536 - val_accuracy: 0.9437\nSAVE THE MODEL\nmodel.save('Flowers_classification_model1.h5')\nTEST THE MODEL\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n# Load the model\nmodel=load_model('Flowers_classification_model1.h5')\nimg=image.load_img(r\"C:\\Users\\Dell\\PycharmProjects\\ibm-projectfiles\\rose.jpg\",target_size=(64,64))\n1/1 [==============================] - 0s 170ms/step\n'rose'\nimg\n\nx=image.img_to_array(img)\nx=np.expand_dims(x,axis=0)\ny=np.argmax(model.predict(x),axis=1)\n# x_train.class_indices\nindex=['daisy','dandelion','rose','sunflower','tulip']\nindex[y[0]]\n1/1 [==============================] - 0s 26ms/step\n'rose'\n ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}